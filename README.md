# Spark

#### 그 동안 Spark로 데이터 레이크 및 SparkML 머신러닝 프로젝트했던 경험 노하우와 소스파일, 설치 방법등을 공개합니다. 
#### 먼저 아파치 스파크(Apache Spark)에 대해 알아보면, 빠르고 범용적인 클러스터 컴퓨팅 시스템을 말합니다. Java, Scala, Python, R의 고수준 API와 표준적인 실행 그래프를 지원하는 최적화된 엔진을 제공합니다. 또한 SQL과 같은 구조화된 데이터 처리를 위한 Spark SQL, 머신 러닝을 위한 MLlib, 그래프 처리를 위한 GraphX, 스파크 스트리밍을 포함한 고급 도구 셋등을 풍부하게 지원합니다.

## 1. 개요
####  1) 스파크는 로컬 PC, Amazon EMR Custer 상에서 Notebook Instance 그리고 최근에 Spark on Kubernetes (EKS)에서 설치와 개발, 실행, 모니터링이 가능합니다.  
####  2) 주의사항: 로컬 PC에서는 3가지 프레임워크 버전이 맞아야 합니다. 현재 저는 Anaconda 3 환경에서 Python 3.8 과 Java 8 version, 그리고 Spark 3.1.2 / Hadoop 2.7 버전을 사용하고 있습니다. 자세한 설치 가이드는 현재 작성 중에 있으니 완성되면 공유하도록 하겠습니다.
####  3) 로컬 PC 시스템과 클라우드 실행 차이점: 로컬과 클라우드에서 Spark 실행은 거의 모두 동일하나 파일을 불러 올때 Path 와 불러올 때 함수가 차이가 납니다. 그외 RDD, SparkSQL, Spark DataFrame, SparkML (MLib)은 동일합니다.
####  

## 2. 아키텍처 

### Resource 

#### 높은 수준에서 모든 Spark 애플리케이션은 사용자의 주요 기능을 실행하고 클러스터에서 다양한 병렬 작업을 실행하는 드라이버 프로그램으로 구성됩니다. Spark가 제공하는 주요 추상화는 병렬로 작동할 수 있는 클러스터의 노드에 걸쳐 분할된 요소 모음인 탄력적인 분산 데이터셋(RDD, Resilient Distrubuted Datasets)입니다. RDD는 Hadoop 파일 시스템(또는 다른 Hadoop 지원 파일 시스템)의 파일 또는 드라이버 프로그램의 기존 Scala 컬렉션으로 시작하여 변환하여 생성합니다. 
#### 이때 사용자는 Spark에 RDD를 메모리에 유지하도록 요청할 수도 있으므로 병렬 작업에서 효율적으로 재사용할 수 있습니다. 마지막으로 RDD는 노드 장애로부터 자동으로 복구됩니다. Spark의 두 번째 추상화는 병렬 작업에서 사용할 수 있는 공유 변수(Shared Variables)입니다. 
#### 기본적으로 Spark가 다른 노드에서 일련의 태스크로 함수를 병렬로 실행할 때 함수에 사용된 각 변수의 복사본을 각 태스크에 전달합니다. 경우에 따라 태스크 간에 또는 태스크들과 드라이버 프로그램 간에 변수를 공유해야 합니다. Spark는 두 가지 유형의 공유 변수를 지원하는 데, 모든 노드의 메모리에 값을 캐시하는 데 사용할 수 있는 브로드캐스트 변수(Broadcast Variables)와 카운터(counter)나 합계(sum)와 같이 "추가"만 되는 변수인 accumulator variable 입니다.
