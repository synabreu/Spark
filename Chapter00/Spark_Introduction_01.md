### 0.1.1 스파크 아키텍처 

### ![Spark 아키텍처](./images/spark01.png)

##### 높은 수준에서 모든 Spark 애플리케이션은 사용자의 주요 기능을 실행하고 클러스터에서 다양한 병렬 작업을 실행하는 드라이버 프로그램으로 구성됩니다. Spark가 제공하는 주요 추상화는 병렬로 작동할 수 있는 클러스터의 노드에 걸쳐 분할된 요소 모음인 탄력적인 분산 데이터셋(RDD, Resilient Distrubuted Datasets)입니다. RDD는 Hadoop 파일 시스템(또는 다른 Hadoop 지원 파일 시스템)의 파일 또는 드라이버 프로그램의 기존 Scala 컬렉션으로 시작하여 변환하여 생성합니다. 
##### 이때 사용자는 Spark에 RDD를 메모리에 유지하도록 요청할 수도 있으므로 병렬 작업에서 효율적으로 재사용할 수 있습니다. 마지막으로 RDD는 노드 장애로부터 자동으로 복구됩니다. Spark의 두 번째 추상화는 병렬 작업에서 사용할 수 있는 공유 변수(Shared Variables)입니다. 
##### 기본적으로 Spark가 다른 노드에서 일련의 태스크로 함수를 병렬로 실행할 때 함수에 사용된 각 변수의 복사본을 각 태스크에 전달합니다. 경우에 따라 태스크 간에 또는 태스크들과 드라이버 프로그램 간에 변수를 공유해야 합니다. Spark는 두 가지 유형의 공유 변수를 지원하는 데, 모든 노드의 메모리에 값을 캐시하는 데 사용할 수 있는 브로드캐스트 변수(Broadcast Variables)와 카운터(counter)나 합계(sum)와 같이 "추가"만 되는 변수인 accumulator variable 입니다.
