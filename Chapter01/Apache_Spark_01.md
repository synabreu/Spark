### 1.2 아파치 스파크를 사용한 분산 컴퓨팅

##### 지난 10년 동안 아파치 스파크는 빅 데이터 처리를 위한 사실상의 표준으로 성장했습니다. 실제로 데이터 분석과 관련된 모든 사람에게 없어서는 안될 도구입니다. 여기에서는 아키텍처 및 구성 요소를 포함하여 아파치 스파크의 기본 사항부터 시작합니다. 그런 다음 PySpark 프로그래밍 API를 시작하여 앞에서 설명한 단어 수 문제를 실제로 구현합니다. 마지막으로 최신 아파치 스파크 3.0 릴리스의 새로운 기능을 살펴보겠습니다.

  - [1.2.1 아파치 스파크 소개](https://github.com/synabreu/Spark/blob/main/Chapter01/Apache_Spark_02.md)
  - [1.2.2 RDD를 사용한 데이터 병렬 처리](https://github.com/synabreu/Spark/blob/main/Chapter01/Apache_Spark_03.md)
  - [1.2.3 고차 함수(Higher-order Function)](https://github.com/synabreu/Spark/blob/main/Chapter01/Apache_Spark_04.md)
  - [1.2.4 아파치 스파크 클러스터 아키텍처](https://github.com/synabreu/Spark/blob/main/Chapter01/Apache_Spark_05.md) 
  - [1.2.5 스파크 시작하기](https://github.com/synabreu/Spark/blob/main/Chapter01/Apache_Spark_06.md)

